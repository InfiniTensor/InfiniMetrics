======================================================================================================================================================
Layer (type (var_name))                            Input Shape               Output Shape              Param #                   Mult-Adds
======================================================================================================================================================
GPT (GPT)                                          [80, 64]                  [80, 1, 50257]            --                        --
├─ModuleDict (transformer)                         --                        --                        --                        --
│    └─Embedding (wte)                             [80, 64]                  [80, 64, 768]             38,597,376                3,087,790,080
│    └─Embedding (wpe)                             [64]                      [64, 768]                 786,432                   50,331,648
│    └─ModuleList (h)                              --                        --                        --                        --
│    │    └─Block (0)                              [80, 64, 768]             [80, 64, 768]             --                        --
│    │    │    └─LayerNorm (ln_1)                  [80, 64, 768]             [80, 64, 768]             1,536                     122,880
│    │    │    └─CausalSelfAttention (attn)        [80, 64, 768]             [80, 64, 768]             --                        --
│    │    │    │    └─Linear (c_attn)              [80, 64, 768]             [80, 64, 2304]            1,771,776                 141,742,080
│    │    │    │    └─Linear (c_proj)              [80, 64, 768]             [80, 64, 768]             590,592                   47,247,360
│    │    │    └─LayerNorm (ln_2)                  [80, 64, 768]             [80, 64, 768]             1,536                     122,880
│    │    │    └─MLP (mlp)                         [80, 64, 768]             [80, 64, 768]             --                        --
│    │    │    │    └─Linear (c_fc)                [80, 64, 768]             [80, 64, 3072]            2,362,368                 188,989,440
│    │    │    │    └─NewGELU (gelu)               [80, 64, 3072]            [80, 64, 3072]            --                        --
│    │    │    │    └─Linear (c_proj)              [80, 64, 3072]            [80, 64, 768]             2,360,064                 188,805,120
│    │    └─Block (1)                              [80, 64, 768]             [80, 64, 768]             --                        --
│    │    │    └─LayerNorm (ln_1)                  [80, 64, 768]             [80, 64, 768]             1,536                     122,880
│    │    │    └─CausalSelfAttention (attn)        [80, 64, 768]             [80, 64, 768]             --                        --
│    │    │    │    └─Linear (c_attn)              [80, 64, 768]             [80, 64, 2304]            1,771,776                 141,742,080
│    │    │    │    └─Linear (c_proj)              [80, 64, 768]             [80, 64, 768]             590,592                   47,247,360
│    │    │    └─LayerNorm (ln_2)                  [80, 64, 768]             [80, 64, 768]             1,536                     122,880
│    │    │    └─MLP (mlp)                         [80, 64, 768]             [80, 64, 768]             --                        --
│    │    │    │    └─Linear (c_fc)                [80, 64, 768]             [80, 64, 3072]            2,362,368                 188,989,440
│    │    │    │    └─NewGELU (gelu)               [80, 64, 3072]            [80, 64, 3072]            --                        --
│    │    │    │    └─Linear (c_proj)              [80, 64, 3072]            [80, 64, 768]             2,360,064                 188,805,120
│    │    └─Block (2)                              [80, 64, 768]             [80, 64, 768]             --                        --
│    │    │    └─LayerNorm (ln_1)                  [80, 64, 768]             [80, 64, 768]             1,536                     122,880
│    │    │    └─CausalSelfAttention (attn)        [80, 64, 768]             [80, 64, 768]             --                        --
│    │    │    │    └─Linear (c_attn)              [80, 64, 768]             [80, 64, 2304]            1,771,776                 141,742,080
│    │    │    │    └─Linear (c_proj)              [80, 64, 768]             [80, 64, 768]             590,592                   47,247,360
│    │    │    └─LayerNorm (ln_2)                  [80, 64, 768]             [80, 64, 768]             1,536                     122,880
│    │    │    └─MLP (mlp)                         [80, 64, 768]             [80, 64, 768]             --                        --
│    │    │    │    └─Linear (c_fc)                [80, 64, 768]             [80, 64, 3072]            2,362,368                 188,989,440
│    │    │    │    └─NewGELU (gelu)               [80, 64, 3072]            [80, 64, 3072]            --                        --
│    │    │    │    └─Linear (c_proj)              [80, 64, 3072]            [80, 64, 768]             2,360,064                 188,805,120
│    │    └─Block (3)                              [80, 64, 768]             [80, 64, 768]             --                        --
│    │    │    └─LayerNorm (ln_1)                  [80, 64, 768]             [80, 64, 768]             1,536                     122,880
│    │    │    └─CausalSelfAttention (attn)        [80, 64, 768]             [80, 64, 768]             --                        --
│    │    │    │    └─Linear (c_attn)              [80, 64, 768]             [80, 64, 2304]            1,771,776                 141,742,080
│    │    │    │    └─Linear (c_proj)              [80, 64, 768]             [80, 64, 768]             590,592                   47,247,360
│    │    │    └─LayerNorm (ln_2)                  [80, 64, 768]             [80, 64, 768]             1,536                     122,880
│    │    │    └─MLP (mlp)                         [80, 64, 768]             [80, 64, 768]             --                        --
│    │    │    │    └─Linear (c_fc)                [80, 64, 768]             [80, 64, 3072]            2,362,368                 188,989,440
│    │    │    │    └─NewGELU (gelu)               [80, 64, 3072]            [80, 64, 3072]            --                        --
│    │    │    │    └─Linear (c_proj)              [80, 64, 3072]            [80, 64, 768]             2,360,064                 188,805,120
│    │    └─Block (4)                              [80, 64, 768]             [80, 64, 768]             --                        --
│    │    │    └─LayerNorm (ln_1)                  [80, 64, 768]             [80, 64, 768]             1,536                     122,880
│    │    │    └─CausalSelfAttention (attn)        [80, 64, 768]             [80, 64, 768]             --                        --
│    │    │    │    └─Linear (c_attn)              [80, 64, 768]             [80, 64, 2304]            1,771,776                 141,742,080
│    │    │    │    └─Linear (c_proj)              [80, 64, 768]             [80, 64, 768]             590,592                   47,247,360
│    │    │    └─LayerNorm (ln_2)                  [80, 64, 768]             [80, 64, 768]             1,536                     122,880
│    │    │    └─MLP (mlp)                         [80, 64, 768]             [80, 64, 768]             --                        --
│    │    │    │    └─Linear (c_fc)                [80, 64, 768]             [80, 64, 3072]            2,362,368                 188,989,440
│    │    │    │    └─NewGELU (gelu)               [80, 64, 3072]            [80, 64, 3072]            --                        --
│    │    │    │    └─Linear (c_proj)              [80, 64, 3072]            [80, 64, 768]             2,360,064                 188,805,120
│    │    └─Block (5)                              [80, 64, 768]             [80, 64, 768]             --                        --
│    │    │    └─LayerNorm (ln_1)                  [80, 64, 768]             [80, 64, 768]             1,536                     122,880
│    │    │    └─CausalSelfAttention (attn)        [80, 64, 768]             [80, 64, 768]             --                        --
│    │    │    │    └─Linear (c_attn)              [80, 64, 768]             [80, 64, 2304]            1,771,776                 141,742,080
│    │    │    │    └─Linear (c_proj)              [80, 64, 768]             [80, 64, 768]             590,592                   47,247,360
│    │    │    └─LayerNorm (ln_2)                  [80, 64, 768]             [80, 64, 768]             1,536                     122,880
│    │    │    └─MLP (mlp)                         [80, 64, 768]             [80, 64, 768]             --                        --
│    │    │    │    └─Linear (c_fc)                [80, 64, 768]             [80, 64, 3072]            2,362,368                 188,989,440
│    │    │    │    └─NewGELU (gelu)               [80, 64, 3072]            [80, 64, 3072]            --                        --
│    │    │    │    └─Linear (c_proj)              [80, 64, 3072]            [80, 64, 768]             2,360,064                 188,805,120
│    │    └─Block (6)                              [80, 64, 768]             [80, 64, 768]             --                        --
│    │    │    └─LayerNorm (ln_1)                  [80, 64, 768]             [80, 64, 768]             1,536                     122,880
│    │    │    └─CausalSelfAttention (attn)        [80, 64, 768]             [80, 64, 768]             --                        --
│    │    │    │    └─Linear (c_attn)              [80, 64, 768]             [80, 64, 2304]            1,771,776                 141,742,080
│    │    │    │    └─Linear (c_proj)              [80, 64, 768]             [80, 64, 768]             590,592                   47,247,360
│    │    │    └─LayerNorm (ln_2)                  [80, 64, 768]             [80, 64, 768]             1,536                     122,880
│    │    │    └─MLP (mlp)                         [80, 64, 768]             [80, 64, 768]             --                        --
│    │    │    │    └─Linear (c_fc)                [80, 64, 768]             [80, 64, 3072]            2,362,368                 188,989,440
│    │    │    │    └─NewGELU (gelu)               [80, 64, 3072]            [80, 64, 3072]            --                        --
│    │    │    │    └─Linear (c_proj)              [80, 64, 3072]            [80, 64, 768]             2,360,064                 188,805,120
│    │    └─Block (7)                              [80, 64, 768]             [80, 64, 768]             --                        --
│    │    │    └─LayerNorm (ln_1)                  [80, 64, 768]             [80, 64, 768]             1,536                     122,880
│    │    │    └─CausalSelfAttention (attn)        [80, 64, 768]             [80, 64, 768]             --                        --
│    │    │    │    └─Linear (c_attn)              [80, 64, 768]             [80, 64, 2304]            1,771,776                 141,742,080
│    │    │    │    └─Linear (c_proj)              [80, 64, 768]             [80, 64, 768]             590,592                   47,247,360
│    │    │    └─LayerNorm (ln_2)                  [80, 64, 768]             [80, 64, 768]             1,536                     122,880
│    │    │    └─MLP (mlp)                         [80, 64, 768]             [80, 64, 768]             --                        --
│    │    │    │    └─Linear (c_fc)                [80, 64, 768]             [80, 64, 3072]            2,362,368                 188,989,440
│    │    │    │    └─NewGELU (gelu)               [80, 64, 3072]            [80, 64, 3072]            --                        --
│    │    │    │    └─Linear (c_proj)              [80, 64, 3072]            [80, 64, 768]             2,360,064                 188,805,120
│    │    └─Block (8)                              [80, 64, 768]             [80, 64, 768]             --                        --
│    │    │    └─LayerNorm (ln_1)                  [80, 64, 768]             [80, 64, 768]             1,536                     122,880
│    │    │    └─CausalSelfAttention (attn)        [80, 64, 768]             [80, 64, 768]             --                        --
│    │    │    │    └─Linear (c_attn)              [80, 64, 768]             [80, 64, 2304]            1,771,776                 141,742,080
│    │    │    │    └─Linear (c_proj)              [80, 64, 768]             [80, 64, 768]             590,592                   47,247,360
│    │    │    └─LayerNorm (ln_2)                  [80, 64, 768]             [80, 64, 768]             1,536                     122,880
│    │    │    └─MLP (mlp)                         [80, 64, 768]             [80, 64, 768]             --                        --
│    │    │    │    └─Linear (c_fc)                [80, 64, 768]             [80, 64, 3072]            2,362,368                 188,989,440
│    │    │    │    └─NewGELU (gelu)               [80, 64, 3072]            [80, 64, 3072]            --                        --
│    │    │    │    └─Linear (c_proj)              [80, 64, 3072]            [80, 64, 768]             2,360,064                 188,805,120
│    │    └─Block (9)                              [80, 64, 768]             [80, 64, 768]             --                        --
│    │    │    └─LayerNorm (ln_1)                  [80, 64, 768]             [80, 64, 768]             1,536                     122,880
│    │    │    └─CausalSelfAttention (attn)        [80, 64, 768]             [80, 64, 768]             --                        --
│    │    │    │    └─Linear (c_attn)              [80, 64, 768]             [80, 64, 2304]            1,771,776                 141,742,080
│    │    │    │    └─Linear (c_proj)              [80, 64, 768]             [80, 64, 768]             590,592                   47,247,360
│    │    │    └─LayerNorm (ln_2)                  [80, 64, 768]             [80, 64, 768]             1,536                     122,880
│    │    │    └─MLP (mlp)                         [80, 64, 768]             [80, 64, 768]             --                        --
│    │    │    │    └─Linear (c_fc)                [80, 64, 768]             [80, 64, 3072]            2,362,368                 188,989,440
│    │    │    │    └─NewGELU (gelu)               [80, 64, 3072]            [80, 64, 3072]            --                        --
│    │    │    │    └─Linear (c_proj)              [80, 64, 3072]            [80, 64, 768]             2,360,064                 188,805,120
│    │    └─Block (10)                             [80, 64, 768]             [80, 64, 768]             --                        --
│    │    │    └─LayerNorm (ln_1)                  [80, 64, 768]             [80, 64, 768]             1,536                     122,880
│    │    │    └─CausalSelfAttention (attn)        [80, 64, 768]             [80, 64, 768]             --                        --
│    │    │    │    └─Linear (c_attn)              [80, 64, 768]             [80, 64, 2304]            1,771,776                 141,742,080
│    │    │    │    └─Linear (c_proj)              [80, 64, 768]             [80, 64, 768]             590,592                   47,247,360
│    │    │    └─LayerNorm (ln_2)                  [80, 64, 768]             [80, 64, 768]             1,536                     122,880
│    │    │    └─MLP (mlp)                         [80, 64, 768]             [80, 64, 768]             --                        --
│    │    │    │    └─Linear (c_fc)                [80, 64, 768]             [80, 64, 3072]            2,362,368                 188,989,440
│    │    │    │    └─NewGELU (gelu)               [80, 64, 3072]            [80, 64, 3072]            --                        --
│    │    │    │    └─Linear (c_proj)              [80, 64, 3072]            [80, 64, 768]             2,360,064                 188,805,120
│    │    └─Block (11)                             [80, 64, 768]             [80, 64, 768]             --                        --
│    │    │    └─LayerNorm (ln_1)                  [80, 64, 768]             [80, 64, 768]             1,536                     122,880
│    │    │    └─CausalSelfAttention (attn)        [80, 64, 768]             [80, 64, 768]             --                        --
│    │    │    │    └─Linear (c_attn)              [80, 64, 768]             [80, 64, 2304]            1,771,776                 141,742,080
│    │    │    │    └─Linear (c_proj)              [80, 64, 768]             [80, 64, 768]             590,592                   47,247,360
│    │    │    └─LayerNorm (ln_2)                  [80, 64, 768]             [80, 64, 768]             1,536                     122,880
│    │    │    └─MLP (mlp)                         [80, 64, 768]             [80, 64, 768]             --                        --
│    │    │    │    └─Linear (c_fc)                [80, 64, 768]             [80, 64, 3072]            2,362,368                 188,989,440
│    │    │    │    └─NewGELU (gelu)               [80, 64, 3072]            [80, 64, 3072]            --                        --
│    │    │    │    └─Linear (c_proj)              [80, 64, 3072]            [80, 64, 768]             2,360,064                 188,805,120
│    └─LayerNorm (ln_f)                            [80, 64, 768]             [80, 64, 768]             1,536                     122,880
├─Linear (lm_head)                                 [80, 1, 768]              [80, 1, 50257]            38,597,376                3,087,790,080
======================================================================================================================================================
